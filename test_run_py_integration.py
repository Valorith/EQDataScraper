#!/usr/bin/env python3
"""
Integration tests for run.py functionality
Tests the actual AppRunner class methods in a safe way
"""

import unittest
import tempfile
import json
import os
import sys
import platform
from pathlib import Path
from unittest.mock import patch, MagicMock

# Add current directory to path
sys.path.insert(0, str(Path(__file__).parent))
from run import AppRunner

class TestRunPyIntegration(unittest.TestCase):
    """Integration tests for run.py AppRunner functionality"""
    
    def setUp(self):
        """Set up test environment with temporary directories"""
        self.temp_dir = tempfile.mkdtemp()
        self.runner = AppRunner()
        
        # Override paths to use temp directory
        self.runner.root_dir = Path(self.temp_dir)
        self.runner.backend_dir = self.runner.root_dir / "backend"
        self.runner.frontend_dir = self.runner.root_dir
        self.runner.config_file = self.runner.root_dir / "config.json"
        self.runner.pids_file = self.runner.root_dir / ".app_pids.json"
        
        # Create directory structure
        self.runner.backend_dir.mkdir(parents=True)
        
    def tearDown(self):
        """Clean up temporary directory"""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_config_loading_and_saving(self):
        """Test configuration loading and saving functionality"""
        # Test default config creation
        config = self.runner.load_config()
        
        # Should have default values
        self.assertEqual(config['backend_port'], 5001)
        self.assertEqual(config['frontend_port'], 3000)
        
        # Test config file was created
        self.assertTrue(self.runner.config_file.exists())
        
        # Test modifying and saving config
        config['backend_port'] = 8080
        self.runner.save_config(config)
        
        # Test loading modified config
        new_config = self.runner.load_config()
        self.assertEqual(new_config['backend_port'], 8080)
        
        print("‚úì Configuration loading and saving works")
    
    def test_port_management(self):
        """Test port availability and conflict management"""
        # Test finding available port
        available_port = self.runner.find_available_port(8000)
        self.assertGreaterEqual(available_port, 8000)
        
        # Test port in use check (should be false for high port numbers)
        is_in_use = self.runner.is_port_in_use(65000)  # Very unlikely to be in use
        self.assertFalse(is_in_use)
        
        print("‚úì Port management works")
    
    @patch('platform.system')
    def test_platform_specific_process_detection(self, mock_platform):
        """Test platform-specific process detection methods"""
        
        # Test Windows path
        mock_platform.return_value = 'Windows'
        with patch('subprocess.run') as mock_run:
            mock_run.return_value = MagicMock(returncode=0, stdout='PID 1234')
            result = self.runner.is_process_running(1234)
            self.assertTrue(result)
            
            # Verify Windows-specific command was used
            mock_run.assert_called_with(
                ['tasklist', '/fi', 'PID eq 1234'],
                capture_output=True, text=True, shell=True
            )
        
        # Test Unix path
        mock_platform.return_value = 'Darwin'
        with patch('os.kill') as mock_kill:
            mock_kill.return_value = None  # Success
            result = self.runner.is_process_running(1234)
            self.assertTrue(result)
            
            # Verify Unix-specific command was used
            mock_kill.assert_called_with(1234, 0)
        
        print("‚úì Platform-specific process detection works")
    
    def test_npm_command_detection(self):
        """Test npm command detection"""
        with patch('subprocess.run') as mock_run:
            # Mock successful npm detection
            mock_run.return_value = MagicMock(returncode=0, stdout='8.0.0')
            
            npm_cmd = self.runner.find_npm_command()
            self.assertIsNotNone(npm_cmd)
            
            # Should have attempted to run npm --version
            mock_run.assert_called()
            
        print("‚úì npm command detection works")
    
    def test_dependency_checking(self):
        """Test dependency checking functionality"""
        # Create mock node_modules structure
        node_modules = self.runner.frontend_dir / "node_modules"
        node_modules.mkdir()
        
        # Create critical packages
        for package in ["vite", "vue"]:
            (node_modules / package).mkdir()
        
        # Create @vitejs structure
        vitejs_dir = node_modules / "@vitejs"
        vitejs_dir.mkdir()
        (vitejs_dir / "plugin-vue").mkdir()
        
        # Mock Python dependencies being available
        with patch('importlib.import_module'):
            with patch.object(self.runner, 'find_npm_command', return_value='npm'):
                with patch('subprocess.run') as mock_run:
                    mock_run.return_value = MagicMock(returncode=0, stdout='16.0.0')
                    
                    # Should pass dependency check
                    result = self.runner.check_dependencies()
                    # May fail due to missing Python deps, but structure should work
                    
        print("‚úì Dependency checking structure works")
    
    def test_first_time_setup_detection(self):
        """Test first-time setup detection"""
        # Initially should detect as not set up
        with patch('importlib.import_module', side_effect=ImportError()):
            is_complete = self.runner._is_setup_complete()
            self.assertFalse(is_complete)
        
        # Create node_modules and packages
        node_modules = self.runner.frontend_dir / "node_modules"
        node_modules.mkdir()
        
        for package in ["vite", "vue"]:
            (node_modules / package).mkdir()
        
        vitejs_dir = node_modules / "@vitejs"
        vitejs_dir.mkdir()
        (vitejs_dir / "plugin-vue").mkdir()
        
        # Mock Python dependencies as available
        with patch('importlib.import_module'):
            is_complete = self.runner._is_setup_complete()
            self.assertTrue(is_complete)
        
        print("‚úì First-time setup detection works")
    
    def test_pid_management(self):
        """Test PID file management"""
        # Test saving PIDs
        mock_process = MagicMock()
        mock_process.poll.return_value = None  # Process running
        mock_process.pid = 1234
        
        self.runner.processes = {"backend": mock_process}
        self.runner.save_pids()
        
        # Test PID file was created
        self.assertTrue(self.runner.pids_file.exists())
        
        # Test loading PIDs
        loaded_pids = self.runner.load_pids()
        self.assertEqual(loaded_pids["backend"], 1234)
        
        print("‚úì PID management works")
    
    @patch('urllib.request.urlopen')
    def test_network_connectivity_check(self, mock_urlopen):
        """Test network connectivity checking"""
        # Test successful connection
        mock_response = MagicMock()
        mock_response.status = 200
        mock_urlopen.return_value.__enter__.return_value = mock_response
        
        result = self.runner._check_network_connectivity()
        self.assertTrue(result)
        
        # Test failed connection
        mock_urlopen.side_effect = Exception("Connection failed")
        result = self.runner._check_network_connectivity()
        # Should return True on generic exceptions (assumes connectivity is fine)
        self.assertTrue(result)
        
        print("‚úì Network connectivity checking works")
    
    @patch('platform.system')
    def test_port_conflict_process_detection(self, mock_platform):
        """Test port conflict process detection across platforms"""
        
        # Test Windows
        mock_platform.return_value = 'Windows'
        with patch('subprocess.run') as mock_run:
            # Mock netstat output
            mock_run.side_effect = [
                MagicMock(returncode=0, stdout='TCP    127.0.0.1:5000    0.0.0.0:0    LISTENING    1234'),
                MagicMock(returncode=0, stdout='"python.exe","1234","Console","1","8,192 K"')
            ]
            
            process_info = self.runner.get_port_conflict_process(5000)
            self.assertIsNotNone(process_info)
        
        # Test macOS
        mock_platform.return_value = 'Darwin'
        with patch('subprocess.run') as mock_run:
            mock_run.side_effect = [
                MagicMock(returncode=0, stdout='1234'),
                MagicMock(returncode=0, stdout='python')
            ]
            
            process_info = self.runner.get_port_conflict_process(5000)
            self.assertEqual(process_info, 'python')
        
        # Test Linux
        mock_platform.return_value = 'Linux'
        with patch('subprocess.run') as mock_run:
            mock_run.return_value = MagicMock(returncode=0, stdout='tcp LISTEN 0 0 127.0.0.1:5000 users:((python,1234,3))')
            
            process_info = self.runner.get_port_conflict_process(5000)
            self.assertIsNotNone(process_info)
        
        print("‚úì Port conflict process detection works across platforms")

def run_integration_tests():
    """Run all integration tests"""
    print("üîß Running run.py Integration Tests")
    print("=" * 60)
    
    # Create test suite
    loader = unittest.TestLoader()
    suite = loader.loadTestsFromTestCase(TestRunPyIntegration)
    
    # Run tests
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    print("\n" + "=" * 60)
    print("üéØ Integration Test Summary")
    print("=" * 60)
    
    if result.wasSuccessful():
        print("‚úÖ All integration tests PASSED!")
        print(f"   Tests run: {result.testsRun}")
        print(f"   Platform: {platform.system()}")
    else:
        print("‚ùå Some integration tests FAILED!")
        print(f"   Failures: {len(result.failures)}")
        print(f"   Errors: {len(result.errors)}")
        
        for test, trace in result.failures + result.errors:
            print(f"   - {test}")
    
    return result.wasSuccessful()

if __name__ == "__main__":
    success = run_integration_tests()
    sys.exit(0 if success else 1)